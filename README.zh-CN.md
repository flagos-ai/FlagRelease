🌐 Language:
[English](README.md) | [简体中文](README.zh-CN.md)

# FlagRelease


   FlagRelease 是由智源研究院研发的一套面向多架构人工智能芯片的大模型自动迁移、适配与发布平台，平台旨在通过自动化、标准化和智能化的适配流程，使主流大模型能够在不同国产人工智能芯片上以更低成本、更高效率完成模型迁移、验证与发版。依托统一、开源的 AI 系统软件栈 FlagOS 提供的跨芯适配能力，FlagRelease 构建了一套标准化流程，实现大模型自动迁移至不同硬件架构、自动评测迁移效果、内置自动部署与调优，并生成多芯版本模型进行发布。基于FlagRelease平台发布的产物，用户可以在 魔搭（ModelScope）或 Hugging Face 的 FlagRelease 页面找到开源大模型的不同芯片版本，下载即可在对应硬件环境上直接使用，无需自行迁移，降低用户迁移成本。
 FlagRelease 平台目前的产出物包括经过迁移和验证的模型文件以及一体化 Docker 镜像，镜像中包括FlagOS核心组件和模型依赖包，用户可以直接应用到对应芯片。同时每个模型版本都提供评测结果作为技术参考，让用户清楚不同硬件上的正确性表现。另外，每个模型发布附带AnythingLLM配置使用方式，帮助用户快速验证迁移模型的可用性，方便用户基于模型进行二次开发。
FlagOS 整体架构如下图所示：
![](assets/flagos.jpeg)

## 模型发布日志

<!-- START:models -->

<!-- END:models -->

## 产出物操作使用示例
FlagRelease 的产出物包括经过验证的大模型文件以及一体化的 FlagOS Docker 镜像。利用这些产出物，用户可以快速在不同硬件上部署和运行大模型，无需自行迁移或配置复杂环境。
操作步骤示例：
1. 下载开源模型权重
  - 通过魔搭（ModelScope）或 Hugging Face 的 FlagRelease 页面，选择所需的大模型及对应芯片版本，直接下载模型权重文件。
2. 下载 FlagOS 镜像
  - 获取官方提供的一体化 Docker 镜像，包含统一的软件栈和硬件适配支持。
3. 部署与运行
  - 将下载的模型权重和 FlagOS 镜像结合，即可在目标硬件上直接运行模型。
  - FlagOS 会自动管理硬件资源，支持多芯片并行计算，无需手动配置环境。

示例应用场景：
- 在科研实验中，快速部署大模型进行推理，无需关注底层硬件差异。
- 在生产环境中，直接使用不同芯片版本的模型进行服务部署，保证性能和稳定性。

